{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers for regression\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='linear')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load and preprocess data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'path_to_training_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='input'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=50, validation_data=validation_generator)\n",
    "\n",
    "# Save the model\n",
    "model.save('NET_counting_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Neutrophil Extracellular Traps (NETs) are already marked with a unique fluorescent color, this simplifies the task of detecting and counting them using a Convolutional Neural Network (CNN). Here’s an optimized pathway to leverage this information for training a CNN:\n",
    "\n",
    "### Step-by-Step Guide\n",
    "\n",
    "1. **Data Collection and Annotation**:\n",
    "   - **Collect Fluorescent Microscopy Images**: Gather a large dataset of microscopy images where NETs are marked with a unique fluorescent marker.\n",
    "   - **Annotation**: Ensure that images are annotated, if necessary, with the number of NETs or their locations. Given the unique color, this can be automated to some extent.\n",
    "\n",
    "2. **Data Preparation**:\n",
    "   - **Color Segmentation**: Pre-process images to isolate the fluorescent color marking the NETs. This can be done using color thresholding techniques.\n",
    "   - **Resize Images**: Ensure all images are of the same size (e.g., 224x224 pixels) for input into the CNN.\n",
    "   - **Normalize Pixel Values**: Normalize the pixel values to a range suitable for CNN input (e.g., [0, 1]).\n",
    "\n",
    "### Example Implementation: Color Segmentation and CNN Training\n",
    "\n",
    "Here is an example of how to preprocess images using color segmentation and then train a CNN using TensorFlow/Keras.\n",
    "\n",
    "#### Color Segmentation\n",
    "\n",
    "First, segment the NETs based on their unique fluorescent color.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def segment_nets(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define the color range for the fluorescent marker\n",
    "    lower_color = np.array([30, 150, 50])\n",
    "    upper_color = np.array([85, 255, 255])\n",
    "    \n",
    "    # Create a mask for the color\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    \n",
    "    # Apply the mask to get the segmented NETs\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    return result, mask\n",
    "\n",
    "# Example usage\n",
    "image = cv2.imread('path_to_fluorescent_image.jpg')\n",
    "segmented_image, mask = segment_nets(image)\n",
    "\n",
    "# Display the original and segmented images\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Segmented NETs')\n",
    "plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### CNN Training\n",
    "\n",
    "Next, use the segmented images to train the CNN.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load the pre-trained VGG16 model without the top layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='linear')(x)  # For counting, use a single output neuron\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load and preprocess data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'path_to_training_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'  # Use 'sparse' if labels are integers (counts)\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    'path_to_validation_data',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('NET_counting_model.h5')\n",
    "```\n",
    "\n",
    "### Steps Breakdown\n",
    "\n",
    "1. **Color Segmentation**:\n",
    "   - Use color thresholding to isolate the fluorescently marked NETs. This preprocesses the image to highlight the regions of interest.\n",
    "\n",
    "2. **Prepare Datasets**:\n",
    "   - Use segmented images to train the model. The segmented images help the CNN to focus on the NETs, reducing the complexity of learning from raw images.\n",
    "\n",
    "3. **Train the CNN**:\n",
    "   - Use the preprocessed (segmented) images to train the CNN. The training process remains similar, but the input data now emphasizes the NETs due to the preprocessing step.\n",
    "\n",
    "4. **Validation and Testing**:\n",
    "   - Validate and test the model using similarly preprocessed images to ensure the model's robustness and accuracy.\n",
    "\n",
    "By using the unique fluorescent marker for NETs, you simplify the detection and counting task for the CNN, which can lead to improved accuracy and efficiency in the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that NETs have a unique shape in addition to being marked with a fluorescent marker, you can leverage this information to further enhance the model’s ability to detect and count them. Here's a detailed approach that incorporates shape information along with the fluorescent marker:\n",
    "\n",
    "### Step-by-Step Guide\n",
    "\n",
    "1. **Data Collection and Annotation**\n",
    "   - **Collect Fluorescent Microscopy Images**: Obtain a large dataset of microscopy images where NETs are marked with a unique fluorescent color.\n",
    "   - **Annotation**: Ensure images are annotated with the number of NETs or their locations.\n",
    "\n",
    "2. **Data Preparation**\n",
    "   - **Color Segmentation**: Pre-process images to isolate the fluorescent color marking the NETs.\n",
    "   - **Shape Feature Extraction**: Use morphological operations to emphasize the unique shapes of NETs.\n",
    "\n",
    "3. **Data Augmentation**: Apply data augmentation techniques to increase the diversity of the training data.\n",
    "\n",
    "4. **Model Design**: Use a CNN architecture, potentially enhancing it with custom layers that focus on both color and shape features.\n",
    "\n",
    "### Implementation Steps\n",
    "\n",
    "#### Step 1: Color Segmentation and Shape Enhancement\n",
    "\n",
    "First, segment the NETs based on their unique fluorescent color and then enhance their shapes.\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def segment_and_enhance_nets(image):\n",
    "    # Convert image to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define the color range for the fluorescent marker\n",
    "    lower_color = np.array([30, 150, 50])  # Adjust these values based on the color\n",
    "    upper_color = np.array([85, 255, 255])\n",
    "    \n",
    "    # Create a mask for the color\n",
    "    mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "    \n",
    "    # Apply the mask to get the segmented NETs\n",
    "    segmented_image = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Convert the segmented image to grayscale\n",
    "    gray = cv2.cvtColor(segmented_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Enhance shapes using morphological operations\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    enhanced = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return segmented_image, enhanced\n",
    "\n",
    "# Example usage\n",
    "image = cv2.imread('path_to_fluorescent_image.jpg')\n",
    "segmented_image, enhanced_shape = segment_and_enhance_nets(image)\n",
    "\n",
    "# Display the original, segmented, and enhanced images\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Segmented NETs')\n",
    "plt.imshow(cv2.cvtColor(segmented_image, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Enhanced Shape')\n",
    "plt.imshow(enhanced_shape, cmap='gray')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### Step 2: CNN Training\n",
    "\n",
    "Next, use the segmented and shape-enhanced images to train the CNN.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define a function to create a combined model\n",
    "def create_combined_model(input_shape):\n",
    "    # Load the pre-trained VGG16 model for color features\n",
    "    base_model_color = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    color_output = base_model_color.output\n",
    "    color_output = GlobalAveragePooling2D()(color_output)\n",
    "    \n",
    "    # Separate input for shape-enhanced images\n",
    "    shape_input = Input(shape=input_shape)\n",
    "    base_model_shape = VGG16(weights='imagenet', include_top=False, input_tensor=shape_input)\n",
    "    shape_output = base_model_shape.output\n",
    "    shape_output = GlobalAveragePooling2D()(shape_output)\n",
    "    \n",
    "    # Concatenate color and shape outputs\n",
    "    combined = concatenate([color_output, shape_output])\n",
    "    \n",
    "    # Add custom layers on top of the combined outputs\n",
    "    x = Dense(1024, activation='relu')(combined)\n",
    "    predictions = Dense(1, activation='linear')(x)  # For counting, use a single output neuron\n",
    "    \n",
    "    # Define the model\n",
    "    model = Model(inputs=[base_model_color.input, shape_input], outputs=predictions)\n",
    "    \n",
    "    # Freeze the layers of the base models\n",
    "    for layer in base_model_color.layers:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model_shape.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_combined_model((224, 224, 3))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load and preprocess data\n",
    "# Assuming you have prepared directories for segmented and enhanced shape images\n",
    "train_generator_color = datagen.flow_from_directory(\n",
    "    'path_to_training_data/segmented',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'  # Use 'sparse' if labels are integers (counts)\n",
    ")\n",
    "\n",
    "train_generator_shape = datagen.flow_from_directory(\n",
    "    'path_to_training_data/enhanced_shape',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "validation_generator_color = datagen.flow_from_directory(\n",
    "    'path_to_validation_data/segmented',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "validation_generator_shape = datagen.flow_from_directory(\n",
    "    'path_to_validation_data/enhanced_shape',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    x=[train_generator_color, train_generator_shape],\n",
    "    epochs=50,\n",
    "    validation_data=([validation_generator_color, validation_generator_shape])\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('NET_counting_model_combined.h5')\n",
    "```\n",
    "\n",
    "### Steps Breakdown\n",
    "\n",
    "1. **Color Segmentation and Shape Enhancement**:\n",
    "   - Use color thresholding to isolate NETs based on their fluorescent marker.\n",
    "   - Apply morphological operations to emphasize the unique shapes of NETs.\n",
    "\n",
    "2. **Prepare Datasets**:\n",
    "   - Create separate datasets for segmented images and shape-enhanced images.\n",
    "   - Use these datasets to train the model.\n",
    "\n",
    "3. **Combined CNN Model**:\n",
    "   - Use VGG16 as the base model for both color features and shape features.\n",
    "   - Combine the outputs of both models and add custom layers for the regression task.\n",
    "\n",
    "4. **Training and Evaluation**:\n",
    "   - Train the combined model on the prepared datasets.\n",
    "   - Validate and test the model using similarly preprocessed images.\n",
    "\n",
    "By leveraging both the unique color and shape of NETs, you can significantly improve the accuracy and robustness of the CNN model for detecting and counting NETs in microscopy images."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
